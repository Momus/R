#+TITLE: ALL My R Learnings.
#+AUTHOR: Dmitri Brengauz
#+STARTUP: hideblocks
#+BABEL: :session *R*

* Notes
*** Coursera
***** R Crash Syntax
******* R's Atomic Classes
********* Character
********* Numeric
          - Double precision real numbers
          - Most numbers, unless specifically labeled as integers
          - Inf :: is a special number that represents infinity:
                   > 1 / 0
                   [1] Inf
          - NaN :: "not a number" can also be used for missing value
                   > 0 / 0
                   [1] NaN
********* Integer
********* Boolean
******* Vectors
        The most basic R object. Everything is really a vector. Vector can
        only contain objects of the same type.
******* Lists
        Contain objects of multiple types. More like Java Arrays?
******* Factors
        Represent categorical data:
        #+BEGIN_SRC text
          x <- factor(c("yes","yes","yes","yes","yes","no", "no", "no", "no"), levels = c("yes", "no"))
          > table(x)
          x
          yes  no 
            5   4 
        #+END_SRC
******* NaN and NA
        NaN is NA but NA is not NaN
******* DataFrames
        Store tabular data. 
        - Specialized type of list where every element has to have the
          same length: each element is a column, and the length is the
          number of rows.
        - Can store different types of objects in each column.
        - Attributes include column names and row names.
        - Usually created with read.table() or read.csv()
        - Use data.matrix() not as.matrix() to coerce frame to matrix.
******* Names!
        - Objects and lists can have names. It's cool but weird:
          #+BEGIN_SRC text
            > x <- 1:3
            > names(x)
            NULL
            > names(x) <- c("Me", "Myself", "I")
            > x
                Me Myself      I 
                 1      2      3 
            > names(x)
            [1] "Me"     "Myself" "I"     
          #+END_SRC
        - column and row names can be set seperatly: colnames() rownames()
******* !!!The Whole POINT: [[https://www.jstatsoft.org/article/view/v059i10][TIDY]] DATA!!!!
********* Each variable has a column
********* Each observation has a row
********* Each type of observational unit forms a table
********* Useful Tidy Data Libraries:
          - ggplot2 :: plotting
          - magrittr :: %>% operator for chaining functions together
          - dplyr :: working with data frames
          - tidyr :: tidy data with spread() and gather()functions
******* Data Manipulation
********* dplyr v tidyverse
          - dplyr is "easer" and produces "tidier code."

***** R-Prog-Env
******* Quiz
        :PROPERTIES:
        :DIR: ./R-env/Week4Quiz
        :END:
        1. What is average Arithmetic.Mean for “Bromine PM2.5 LC” in
           the state of Wisconsin in this dataset?
           1. Use the readr package to read the
              daily_SPEC_2014.csv.bz2 data file in to R
              #+BEGIN_SRC R
                if (!exists("daily_SPEC_2014"))
                {daily_SPEC_2014 <- read.csv("./data/daily_SPEC_2014.csv.bz2") }
                print("Object Creation Finished!")
                format(object.size(daily_SPEC_2014), units = "auto")
              #+END_SRC

                #+RESULTS:

           2. average Arithmetic.Mean
              #+BEGIN_SRC R
                mean((daily_SPEC_2014 
                      %>% filter(`Parameter.Name` == "Bromine PM2.5 LC"
                               , `State.Name` == "Wisconsin") 

                      %>% select(`Arithmetic.Mean`))$Arithmetic.Mean)
              #+END_SRC

        2. Which constituent Parameter.Name has the highest average level?a
           1. Calculate the average of each chemical constituent
              across all states, monitoring sites and all time points.

           2. Constituent Parameter.Name with the highest average level?
              #+BEGIN_SRC R
                head(daily_SPEC_2014 %>%
                     group_by(`Parameter.Name`) %>%
                     summarise(mean = mean(`Arithmetic.Mean`)) %>%
                     arrange(desc(mean)), 17)
              #+END_SRC
        3. Which monitoring site has the highest average level of
           “Sulfate PM2.5 LC” across all time?
           Indicate the state code, county code, and site number.
           #+BEGIN_SRC R
             head(daily_SPEC_2014 %>%
                  filter(`Parameter.Name` == "Sulfate PM2.5 LC") %>%
                  group_by(`State.Code`, `County.Code`, `Site.Num`) %>%
                  summarise(mean = mean(`Arithmetic.Mean`)) %>%
                  arrange(desc(mean)))
           #+END_SRC
        4. What is the absolute difference in the average levels of
           “EC PM2.5 LC TOR” between the states California and
           Arizona, across all time and all monitoring sites?
           #+BEGIN_SRC R
             ca_vs_az <- daily_SPEC_2014 %>%
                 filter(`Parameter.Name` == "EC PM2.5 LC TOR"
                      , grepl('Calif|Ariz', `State.Name` )) %>%
                 group_by(`State.Name`) %>%
                 summarise(mean = mean(`Arithmetic.Mean`)) %>%
                 arrange(desc(mean))

             print(ca_vs_az[1,2] - ca_vs_az[2,2])
           #+END_SRC
        5. What is the median level of “OC PM2.5 LC TOR” in the
           western United States, across all time? Define western as
           any monitoring location that has a Longitude LESS THAN
           -100.
           #+BEGIN_SRC R
             median((daily_SPEC_2014 %>%
                     filter(`Parameter.Name` == "OC PM2.5 LC TOR"
                          , `Longitude` < -100) %>%
                     select(`Arithmetic.Mean`))$Arithmetic.Mean)
           #+END_SRC
        6. How many monitoring sites are labelled as both RESIDENTIAL
           for "Land Use" and SUBURBAN for "Location Setting"?
           #+BEGIN_SRC R
             dim(aqs_sites %>%
                 filter(`Land Use` == "RESIDENTIAL"
                      , `Location Setting` == "SUBURBAN"))
           #+END_SRC
        7. What is the median level of “EC PM2.5 LC TOR” amongst
           monitoring sites that are labelled as both “RESIDENTIAL”
           and “SUBURBAN” in the eastern U.S., where eastern is
           defined as Longitude greater than or equal to -100?
           #+BEGIN_SRC R

             big_one <- full_join(aqs_sites, daily_SPEC_2014)

             median((big_one %>%
                     filter(`Land Use` == "RESIDENTIAL"
                          , `Location Setting` == "SUBURBAN"
                          , `Parameter.Name` == "EC PM2.5 LC TOR"
                          , `Longitude` >= -100) %>%
                     select(`Arithmetic.Mean`))$`Arithmetic.Mean`)
           #+END_SRC
        8. Amongst monitoring sites that are labeled as COMMERCIAL for
           "Land Use", which month of the year has the highest average
           levels of "Sulfate PM2.5 LC"?
           #+BEGIN_SRC R
             commercial_sulfate <- (big_one %>%
                 filter(`Land Use` == "COMMERCIAL",
             `Parameter.Name` == "Sulfate PM2.5 LC") %>%
             select(date = `Date.Local`, obs = `Arithmetic.Mean`))

             commercial_sulfate  %>%
                 group_by(month = floor_date(as.POSIXct.Date(date), "month")) %>%
                 summarise(mean = mean(obs)) %>%
                 arrange(desc(mean))
           #+END_SRC
        9. for how many days is the sum of "Sulfate PM2.5 LC" and
           "Total Nitrate PM2.5 LC" greater than 10?
           #+BEGIN_SRC R
             ## Shrink the data to what we need to make it more manageble.
             local_Sulfate_Nitrate <- (big_one %>%
                                       filter(`State Code` == 6
                                            , `County Code` == 65
                                            , `Site Number` == 8001
                                            , grepl('Sulfate PM2.5 LC|Total Nitrate PM2.5 LC',
                                                    `Parameter.Name` )) %>%
                                       select(date = `Date.Local`
                                            , parameter = `Parameter.Name`
                                            , obs = `Arithmetic.Mean`))


             ## Get the mean values for each day on each parameter
             summarry_local_Sulfate_Nitrate <- local_Sulfate_Nitrate %>% 
             group_by(date, parameter) %>%
                 summarise(mean(`obs`)local_Sulfate_Nitrate %>% 
                                      group_by(date, parameter) %>%
                                      summarise(mean(`obs`)))


             ((summarry_local_Sulfate_Nitrate %>%
               filter(grepl('ulfate' , parameter)))
                 +
                 (summarry_local_Sulfate_Nitrate %>%
                  filter(grepl('itra' ,parameter)))) %>%
                 filter(`mean(obs)` > 10)
           #+END_SRC
        10. Which monitoring site in the dataset has the highest
            correlation between "Sulfate PM2.5 LC" and "Total Nitrate
            PM2.5 LC" across all dates?
            #+BEGIN_SRC R
              all_Sulfate <- (daily_SPEC_2014
                  %>% filter(`Parameter.Name` == "Sulfate PM2.5 LC")
                  %>% select(State=`State.Code`
                           , County=`County.Code`
                           , Site=`Site.Num`
                           , obs=`Arithmetic.Mean`
                           , date=`Date.Local`)
                  %>% group_by(State
                             , County
                             , Site
                             , date)
                  %>% summarise(value_Sulfate=mean(`obs`)))

              total_total__Nitrate <- (daily_SPEC_2014 
                  %>% filter(`Parameter.Name` == "Total Nitrate PM2.5 LC") 
                  %>% select(State=`State.Code`
                           , County=`County.Code`
                           , Site=`Site.Num`
                           , obs=`Arithmetic.Mean`
                           , date=`Date.Local`)
                  %>% group_by(State
                             , County
                             , Site
                             , date)
                  %>% summarise(value_Nitrate=mean(`value`)))

              both_S_and_N <- (inner_join(total_total__Nitrate
                                       , all_Sulfate))


              both_S_and_N
              %>% group_by(State, County, Site)
              %>% summarise(correlation=cor(`value_Sulfate`
                                          , `value_Nitrate`
                                          , use = "complete.obs"))
              %>% arrange(desc(correlation))
            #+END_SRC

***** R-advc-prog
******* Quiz Errata:
        What does the traceback() function do?
        returns the state of the function call stack just before an occurred
        -- should be "prints the state"
        it is the function .traceback() that returns the call stack, traceback() pretty-prints it.
        Maybe it's a small difference, but it was emphasized in traceback's docs.
******* Reading Notes
***** Visualization: Project
******* Download storm data:
        - Atlantic basin, 1988-2015
******* Tidy Dataset into "long" format
        1. add column for storm_id: combining storm name and year
        2. format long:
           1. numeric
           2. negative values for Western hemisphere
        3. format and combine date and time columns to create datetime
           for each observation.
        4. Convert data to a "long" format:
           1. separate rows for each of the three wind speeds for wind radii
******* Subset to the specific hurricacane (Ike) and to a single observation time.
******* Write 
******* 
***** Packages
******* Mandatory structure:
*********  DESCRIPTION
          - contains meta data used by R and repos.
            - name
            - version number
            - author and maintainer info
            - license
            - dependencies.
*********  NAMESPACE
          "Specifies the interface to the package that is presented to
          the user."
          - export() :: indicate which functions in the package are
                        exported to the user.
          - import() :: imports needed functions. Takes a package name
                        and makes all functions in that package
                        available.

          - importedFrom() :: allows the import of specific functions
                              from a package.
                              #+BEGIN_SRC R
                                importFrom("grDevices", "colorRampPalette", "gray")
                              #+END_SRC
********* ./R :: the code
********* ./man :: the docs
          Used to be: written directly in a \LaTeX format. Nowadays,
          roxygen2 docs are written into the code files, then
          generated.

******* Function's full name:
        - <package name>::<exported function name>
        - can be used to call a function not specifically exported by
          a package.
******* Loading vs Attaching
        - When a package is loaded by another package, it's name space
          is made available only to that package.
        - When a package attaches a name space, it is placed on the
          search list, making it visible to the user and other packages.
        
******* Documentation:
        - Longer docs like tutorials or overviews of the whole package
        - Shorter, function-specific help files
********* Vignette
          - bundled with both CRAN and _maybe_ git hub. Unnecessary if
            git-hub only.
          - stored in the ./vignettes sub directory
          - devtools::use_vignette("model details") creates them.
            - remember to update the index entry in the vignette's
              YAML code to add real title, & c.
          - more than one allowed per package, but one should give
            general overview.
          - 
********* README
          - Git-hub wants this.
          - To include R code, use devtools to README.Rmd 
********* 
*** [[http://r4ds.had.co.nz/][R]] for Data Science
***** Data transformation
******* Exercises
***** Data visualisation
*** Murrell: R Graphics 2nd Ed
***** Chapter 5: The ggplot2 Package
******* Setup for data for examples:
        #+BEGIN_SRC R
          data("mtcars")
          mtcars2 <- mtcars
          mtcars2$trans <- factor(mtcars$am, 
                                 levels=0:1, 
                                 labels=c("automatic", "manual"))
          mtcars2$gear <- as.factor(mtcars$gear)
          mtcars2$am <- NULL
          mtcars2$vs <- NULL
          mtcars2$drat <- NULL
          mtcars2$carb <- NULL
          mtcars2$wt <- NULL
          mtcars2$hp <- NULL
          mtcars2$qsec <- NULL
          p <- ggplot(mtcars2)
        #+END_SRC
******* Map vs set aesthetic:
        In the graph
        #+BEGIN_SRC R
          p + geom_point(aes(x=disp, y=mpg, shape=gear),
                         size=4)
        #+END_SRC
        The variable "gear" is _mapped_ to the aesthetic shape in the
        aes() function call. Howervever, the "size" aesthetic is _set_
        to a constant value outside of the aes() call.
******* All geoms have the following aesthetics:
        - color
        - size
        - group
******* Scales
        Scales are usually added automatically, but you can add a
        scale component is to override various derails like:
        - the labels of the axes:
          #+BEGIN_SRC R
          p + geom_point(aes(x=disp, y=mpg)) +
              scale_y_continuous(name="miles per gallon") +
              scale_x_continuous(name = "displacement (cu.in.)")
          #+END_SRC
        - limits of the axes:
          #+BEGIN_SRC R
            p + geom_point(aes(x=disp, y=mpg)) +
                scale_y_continuous(name = "miles per gallon",
                                   limits = c(0,40))
          #+END_SRC
        - change the colors used on the scale:
          #+BEGIN_SRC R
            p + geom_point(aes(x=disp, y=mpg, 
                               color=trans), size=4) +
                scale_y_continuous(name = "miles per gallon") +
                scale_color_manual(values=c(automatic=gray(2/3),
                                            manual=grey(1/3)))
          #+END_SRC
******* Statistical transformations
        Either use a stat_layer:
        #+BEGIN_SRC R
        p + geom_smooth(aes(x=disp, y=mpg), method="lm")
        #+END_SRC
        or you can modify in the geom_ call:
        #+BEGIN_SRC R
        p + geom_line(aes(x=disp, y=mpg), stat = "smooth", method="loess")
        #+END_SRC
        won't work without the "method" parameter.
******* The `group` aesthetic
        Groups things:
        #+BEGIN_SRC R
          p + geom_point(aes(x=disp, y=mpg)) + 
              stat_smooth(aes(x=disp, y=mpg, group=trans), 
                          method = "lm")
        #+END_SRC
******* Position Adjustments
        #+BEGIN_SRC R
          p + geom_bar(aes(x=trans, fill=factor(cyl)), color="black") +
              scale_fill_manual(values = gray(1:3/3))
        #+END_SRC
        This automatically "adjusts" the position of the bars to stack one on top of
        the other. You can also have them side by side:
        #+BEGIN_SRC R
          p + geom_bar(aes(x=trans, fill=factor(cyl)), color="black",
                       position = "dodge") +
              scale_fill_manual(values = gray(1:3/3))
        #+END_SRC
        Or as fill:
        #+BEGIN_SRC R
          p + geom_bar(aes(x=trans, fill=factor(cyl)), color="black",
                       position = "fill") +
              scale_fill_manual(values = gray(1:3/3))
        #+END_SRC
        expands bars to use all available space and produces a spine plot.
******* Coordinate transformations
********* Use log axes on a plot:
          #+BEGIN_SRC R
            p + geom_point(aes(x=disp, y=mpg)) +
                scale_x_continuous(trans="log") +
                scale_y_continuous(trans="log") +
                geom_line(aes(x=disp, y=mpg),
                          stat = "smooth",
                          method = "lm")
          #+END_SRC
          Note the stat is calculated after transformation, so the
          "smooth" line is based on the log axes.
********* Coordinate Sty stems
          #+BEGIN_SRC R
            p + geom_point(mapping =  aes(x=disp, y=mpg)) +
                scale_x_continuous(trans="log") +
                scale_y_continuous(trans="log") +
                geom_line(mapping = aes(x=disp, y=mpg), stat="smooth",
                          method="lm") +
                coord_trans(x="exp", y="exp")
          #+END_SRC
          In this case the coord_trans reverse the effect of the log
          scales.
          You can also do polar coordinates:
          #+BEGIN_SRC R
            p + geom_bar(mapping = aes(x="", fill=trans)) +
                scale_fill_manual(values = gray(1:2/3)) +
                coord_polar(theta="y")
          #+END_SRC
******* Facets
        I don't care right now
******* Themes
        
        

* Emacs Speaks Statistics Tutorial
*** Installation
***** Melpa (package-install ess)
***** use-package
      #+BEGIN_SRC emacs-lisp
        (use-package ess
          :ensure t
          :init (require 'ess-site))
      #+END_SRC
***** Swirl
******* Set a default [[https://cran.r-project.org/mirrors.html][mirror]]
        Make sure that the package `openssl-devel` is installed, then:
        ~/.Rprofile
        /usr/lib64/R/library/base/R/Rprofile
        #+BEGIN_SRC R
          # set a CRAN mirror
           local({r <- getOption("repos")
                 r["CRAN"] <- "http://my.local.cran"
                 options(repos=r)})
        #+END_SRC
* [[https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/][Bare Minumum]] R Packages.
*** Needed tools:

